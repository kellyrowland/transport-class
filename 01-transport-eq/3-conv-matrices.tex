\documentclass[12pt]{article}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}

\usepackage{setspace}
\onehalfspacing

\usepackage{amssymb}
%% The amsthm package provides extended theorem environments
\usepackage{amsthm}
\usepackage{epsfig}
\usepackage{times}
\renewcommand{\ttdefault}{cmtt}
\usepackage{amsmath}
\usepackage{graphicx} % for graphics files

% Draw figures yourself
\usepackage{tikz} 

% The float package HAS to load before hyperref
\usepackage{float} % for psuedocode formatting
\usepackage{xspace}

% from Denovo Methods Manual
\usepackage{mathrsfs}
\usepackage[mathcal]{euscript}
\usepackage{color}
\usepackage{array}

\usepackage[pdftex]{hyperref}
\usepackage[parfill]{parskip}

% math syntax
\newcommand{\nth}{n\ensuremath{^{\text{th}}} }
\newcommand{\ve}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\Macro}{\ensuremath{\Sigma}}
\newcommand{\rvec}{\ensuremath{\vec{r}}}
\newcommand{\vecr}{\ensuremath{\vec{r}}}
\newcommand{\vecx}{\ensuremath{\vec{x}}}
\newcommand{\vecy}{\ensuremath{\vec{y}}}
\newcommand{\omvec}{\ensuremath{\hat{\Omega}}}
\newcommand{\vOmega}{\ensuremath{\hat{\Omega}}}
\newcommand{\sigs}{\ensuremath{\Sigma_s(\rvec,E'\rightarrow E,\omvec'\rightarrow\omvec)}}
\newcommand{\el}{\ensuremath{\ell}}
\newcommand{\sigso}{\ensuremath{\Sigma_{s,0}}}
\newcommand{\sigsi}{\ensuremath{\Sigma_{s,1}}}

\newtheorem{theorem}{Theorem}
\newenvironment{definition}[1][Definition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{example}[1][Example]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}


%---------------------------------------------------------------------------
\begin{document}
\begin{center}
{\bf NE 155/255, Fall 2019 \\
Vector Convergence, Matrix Norms and Convergence \\ September 06, 2019}
\end{center}

\setlength{\unitlength}{1in}
\begin{picture}(6,.1) 
\put(0,0) {\line(1,0){6.25}}         
\end{picture}

%------------------------------------------------------------------------------

\underline{\textbf{Basic Theorems of Convergence}}

\begin{definition}
A sequence of vectors $\{\vecx^{(k)}\}_{k=1}^\infty$ in $\mathbb{R}^n$ is said 
to \textit{converge} to $\vecx$ with respect to norm $||\cdot||$ if given any
$\varepsilon > 0$ there exists an integer $N(\varepsilon)$ such that

\[
||\vecx^{(k)} - \vecx|| < \varepsilon
\quad \text{for all}  \quad k\geq N(\varepsilon).
\]
\end{definition}

\begin{theorem}
The sequence of vectors $\{\vecx^{(k)}\}_{k=1}^\infty\rightarrow \vecx$ in
$\mathbb{R}^n$ with respect to $||\cdot ||_\infty$ iff

\[
\lim_{k\rightarrow\infty}x_i^{(k)} =
x_i \quad \text{for each} \quad i=1,2,...,n.
\]
\end{theorem}
\pagebreak

\begin{proof}
$(\hookrightarrow)$

Let $\displaystyle{\lim_{k\rightarrow\infty}}||\vecx^{(k)}||_\infty =
||\vecx||_\infty$. Then for any $\varepsilon > 0$, there exists
$N(\varepsilon)$ such that

\[
||\vecx^{(j)}-\vecx^{(m)}||_\infty <\varepsilon \quad
\text{for all}\quad j,m > N(\varepsilon).
\]

Thus

\[
\max_{1\leq i\leq n}|x_i^{(j)}-x_i^{(m)}| <\varepsilon\quad
\text{for all}\quad j,m > N(\varepsilon),
\]

implying that

\[
|x_i^{(j)}-x_i^{(m)}| <\varepsilon\quad \text{for all}\quad i \quad
\text{and for all}\quad j,m > N(\varepsilon).
\]

Therefore,

\[
\lim_{k\rightarrow\infty}x_i^{(k)} = x_i \quad
\text{for each} \quad i=1,2,...,n.
\]
\end{proof}
\begin{proof}
$(\hookleftarrow)$

Let

\[
\lim_{k\rightarrow\infty}x_i^{(k)} = x_i \quad
\text{for each} \quad i=1,2,...,n.
\]

Then for any $\varepsilon > 0$, there exists $N(\varepsilon)$ such that

\[
|x_i^{(j)}-x_i^{(m)}| <\frac{\varepsilon}{2}\quad
\text{for all}\quad i \quad \text{and for all}\quad j,m > N(\varepsilon).
\]

Taking the limit as $m\rightarrow\infty$, we have

\[
|x_i^{(j)}-x_i| \leq \frac{\varepsilon}{2}\quad
\text{for all}\quad i \quad \text{and for all}\quad j > N(\varepsilon).
\]

Thus,

\[
\max_{1\leq i \leq n}|x_i^{(j)}-x_i| \leq \frac{\varepsilon}{2}\quad
\text{for all}\quad j > N(\varepsilon),
\]

which means that

\[
\lim_{j\rightarrow\infty}||\vecx^{(j)}-\vecx||_\infty \leq
\frac{\varepsilon}{2} < \varepsilon.
\]
\end{proof}

\begin{theorem}
For each $\vecx \in \mathbb{R}^n$:
\begin{itemize}
\item[a.] $||\vecx||_\infty \leq ||\vecx||_2 \leq \sqrt{n}||\vecx||_\infty$
\item[b.] $||\vecx||_2 \leq ||\vecx||_1 \leq \sqrt{n}||\vecx||_2$
\item[c.] $||\vecx||_\infty \leq ||\vecx||_1 \leq n||\vecx||_\infty$
\end{itemize} 
\end{theorem}

\begin{proof}
We give the proof for $(a.)$:  
\[
||\vecx||_2 = ||\vecx||_\infty
\left(\sum_{i=1}^n\frac{x_i^2}{||\vecx||_\infty^2}\right)^{1/2} \leq
||\vecx||_\infty\sqrt{n},
\]

because $x_i/||\vecx||_\infty \leq 1$ for all $i$.

Moreover, there is a $i$ such that $||\vecx||_\infty=|x_i|$, therefore

\[
\left(\sum_{i=1}^n\frac{x_i^2}{||\vecx||_\infty^2}\right)^{1/2}\geq 1
\]

and

\[
||\vecx||_2 = ||\vecx||_\infty
\left(\sum_{i=1}^n\frac{x_i^2}{||\vecx||_\infty^2}\right)^{1/2} \geq
||\vecx||_\infty.
\]
\end{proof}

Note: As a corollary of this theorem, convergence in the $l_1, l_2,$ and
$l_\infty$ norms is equivalent.

\underline{\textbf{Matrix Norms}}

We need to extend our definitions to include matrices.

\begin{definition}
A \textit{Matrix Norm} on the set of all $n \times n$ matrices is a 
real-valued function $||\cdot||$ defined on this set that satisfies the 
following properties for all $n \times n$ matrices $A$ and $B$ and all real 
numbers $\alpha$:

\begin{enumerate}
\item $|| A|| \geq 0$ 
\item $|| A|| = 0$ iff $A = 0$ (all zero entries)
\item $|| \alpha A|| = |\alpha| ||A||$ (scalar multiplication)
\item $|| A + B|| \leq ||A|| + ||B||$ (triangle inequality)
\end{enumerate}

In this course, in the case of square matrices, we will deal with 
submultiplicative norms, which also satisfy

\begin{enumerate}
\item[5.] $|| AB|| \leq ||A||\, ||B||$
\end{enumerate}
\end{definition}

\vspace*{1em}

The following theorem is offered without proof:

\begin{theorem} (Natural or Induced Matrix Norm)\\
If $||\cdot||$ is a vector norm on $\mathbb{R}^n$, then
\[
||A|| = \max_{||\vecx|| =1} ||A\vecx||
\]
is a matrix norm.
\end{theorem}

\vspace*{1em}

The natural norm describes how a matrix stretches unit vectors relative to 
that norm. For any $\vecy \ne 0$, $\vecx = \vecy/||\vecy||$ is a unit vector,
and

\[
\max_{||\vecx||=1}||Ax|| =
\max_{||\vecy||\ne 0}\left\Vert A\frac{\vecy}{||\vecy||}\right\Vert =
\max_{||\vecy||\ne 0}\frac{||A\vecy||}{||\vecy||}.
\] 

\vspace*{1em}
\underline{\textbf{Common Norms}}

\begin{itemize}
\item $||A||_1 = \displaystyle{\max_{1\leq j\leq n}}
      \displaystyle{\sum_{i=1}^m}|a_{ij}|$ = largest absolute column sum.
\item $||A||_\infty = \displaystyle{\max_{1\leq i\leq m}}
      \displaystyle{\sum_{i=1}^n}|a_{ij}|$ = largest absolute row sum. 
\item In the special case of the Euclidean norm, the induced matrix norm is 
      the \textit{Spectral Norm}.
The spectral norm of a matrix $A$ is the largest singular value of $A$; i.e. 
the square root of the largest eigenvalue of the positive-semidefinite matrix
$A^*A$:

\[
||A||_2 = \sqrt{\lambda_{max}(A^* A)} = \sigma_{max}(A).
\]

It can be shown that

\[
||A||_2 \leq \left(\sum_{i=1}^m\sum_{j=1}^n |a_{ij}|^2\right)^{1/2} = ||A||_F,
\]

where the right-hand side is the Frobenius norm, or $L_{2,2}$ norm. The 
equality holds if and only if the matrix $A$ is a rank-one matrix or a zero 
matrix.
\end{itemize}
\pagebreak

\begin{example}
Consider 
\[
A = \left(\begin{array}{cc}
2 & 0  \\ -1 & 1 
\end{array}
\right).
\]
Then
\begin{itemize}
\item[i.] $||A||_1 = 3$
\item[ii.] $||A||_\infty = 2$
\item[iii.] $||A||_2 = \sqrt{3+\sqrt{5}} \approx 2.2882$
\end{itemize}
\end{example}

\begin{center}$-----------------$\end{center}
\vspace*{1em}


\underline{\textbf{Convergence and Spectral Radius}}

\begin{definition}
An $n\times n$ matrix $A$ is convergent if
\[
\lim_{k\rightarrow\infty}(A^k)_{ij} = 0,
\]
for each  $i,j=1,2,...,n$.
\end{definition}

\vspace*{1em}

\begin{example}
Consider 
\[
A = \left(\begin{array}{cc}
\frac{1}{2} & 0 \\ \frac{1}{4} & \frac{1}{2}
\end{array}
\right).
\]
We can see that
\[
A^k =\left(\begin{array}{cc}
 \frac{1}{2^k} & 0 \\ \frac{k}{2^{k+1}} & \frac{1}{2^k}
\end{array}
\right) \rightarrow 0
\]
as $k\rightarrow \infty$.
\end{example}

\begin{center}$-----------------$\end{center}
\vspace*{1em}

\begin{definition}
The spectral radius, $\rho(A)$, of a matrix $A$ is defined by
\[
\rho(A) = \max |\lambda|,
\]
where $\lambda$ is an eigenvalue of $A$. 
\end{definition}

\vspace*{1em}

The spectral radius provides a valuable measure of the eigenvalues, which 
helps determine if a numerical scheme will converge.

\vspace*{1em}

\begin{theorem}
If $A \in \mathbb{R}^{n\times n}$, then $\rho(A)\leq ||A||$ for any natural 
norm $||\cdot||$.
\end{theorem}

\begin{proof}
Let $||\vecx||$ be a unit eigenvector of $A$ with respect to the eigenvalue 
$\lambda$. Then

\[
|\lambda| = |\lambda|\, ||\vecx|| = ||\lambda\vecx|| =
||Ax|| \leq ||A||\, ||x|| = ||A||.
\]

Thus,

\[
\rho(A) = \max|\lambda|\leq ||A||.
\]

If $A$ is symmetric, then $\rho(A) = ||A||_2$.
\end{proof}

\vspace*{1em}

The following theorem is given here without proof. It will be used to prove 
Gelfand's Formula.

\begin{theorem}
Let $A\in \mathbb{C}^{n\times n}$ with spectral radius $\rho(A)$; then
$\rho(A)<1$ iff

\[
\lim_{k\rightarrow\infty} A^k = 0.
\]

Moreover, if $\rho(A)>1$ , $||A^k||$ is not bounded for increasing values of
$k$.
\end{theorem}

\begin{theorem}
(Gelfand's Formula)

For any matrix norm $||\cdot||$, we have
\[
\rho(A) = \lim_{k\rightarrow\infty} ||A^k||^{1/k}.
\]
\end{theorem}
\begin{proof}
For any $\varepsilon>0$ we construct the following two matrices:
\[
A_{\pm} = \frac{1}{\rho(A)\pm\varepsilon}A.
\]
Then
\[
\rho(A_{\pm}) = \frac{\rho(A)}{\rho(A)\pm\varepsilon},
\]
which implies that $\rho(A_+) < 1 < \rho(A_-)$.

Using Theorem \textbf{6}, there exists $N_+ \in \mathbb{N}$ such that $\forall$
$k\geq N_+$, we have $||A_+^k|| <1$ and therefore

\[
\forall\,\, k \geq N_+ \quad ||A^k|| < (\rho(A)+\varepsilon)^k,
\]

and

\[
\forall\,\, k \geq N_+ \quad ||A^k||^{1/k} < \rho(A)+\varepsilon.
\]

Applying Theorem \textbf{6} to $A_-$ implies that $||A_-^k||$ is not bounded 
and there exists $N_- \in \mathbb{N}$ such that $\forall$ $k\geq N_-$ we have
$||A_-^k|| >1$ and therefore 

\[
\forall\,\, k \geq N_- \quad ||A^k|| > (\rho(A)-\varepsilon)^k,
\]

and

\[
\forall\,\, k \geq N_- \quad ||A^k||^{1/k} > \rho(A)-\varepsilon.
\]

Let $N = max\{N_+,N_-\}$, then we have that $\forall$ $\varepsilon>0$, there 
is $N\in\mathbb{N}$ such that $\forall$ $k\geq N$

\[
\rho(A)-\varepsilon < ||A^k||^{1/k} < \rho(A) + \varepsilon
\]

which implies that

\[
\lim_{k\rightarrow\infty}||A^k||^{1/k} = \rho(A).
\]
\end{proof}

Finally, we have the following result, offered without proof:

\begin{theorem}
The following statements are equivalent:
\begin{itemize}
\item[a.] $A$ is a convergent matrix
\item[b.] $\displaystyle{\lim_{n\rightarrow\infty}}||A^n|| = 0$ for some 
          natural norm
\item[c.] $\displaystyle{\lim_{n\rightarrow\infty}}||A^n|| = 0$ for all 
          natural norms
\item[d.] $\rho(A)<1$
\item[e.] $\displaystyle{\lim_{n\rightarrow\infty}}A^n\vecx = 0$ for every
          $\vecx$
\end{itemize}
\end{theorem}

\end{document}
